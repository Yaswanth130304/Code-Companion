{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b43af3-33f7-44b0-b966-e4a54955067d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.8/dist-packages (0.23.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 24.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d5aa85-f61e-40d4-a383-829d7e1f4d78",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5142ea83614a62ac1c16112163b1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb9a019-861c-4199-b175-54a00487af9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import argparse\n",
    "import numpy as np\n",
    "import copy\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  4 10:04:20 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.10   Driver Version: 470.141.10   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    56W / 400W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4944d6e-66a7-40cf-981f-ce28e06e62c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090db44c-70d2-4568-b500-80c48303dd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    model_size = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return \"{}M\".format(round(model_size / 1e+6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0464a19-180a-4b58-9ff9-be5bb8c60468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freeze_decoder_except_xattn_codegen(model):\n",
    "    print(f'Para before freezing: {model.num_parameters()}, trainable para: {get_model_size(model)}')\n",
    "    for param in model.decoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_decoder_layers = model.decoder.config.n_layer\n",
    "    for i in range(num_decoder_layers):\n",
    "        each_decoder_layer = model.decoder.transformer.h[i]\n",
    "        if hasattr(each_decoder_layer, 'crossattention'):\n",
    "            for param in each_decoder_layer.crossattention.parameters():\n",
    "                param.requires_grad = True\n",
    "            each_decoder_layer.crossattention.to(torch.float32)\n",
    "\n",
    "        if hasattr(each_decoder_layer, 'alpha_xattn'):\n",
    "            each_decoder_layer.alpha_xattn.requires_grad = True\n",
    "    print(f'Para after freezing: {model.num_parameters()}, trainable para: {get_model_size(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8937dcb9-d8a5-43d8-9104-7d19b31b9ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "def apply_lora_adapter(model):\n",
    "    # Initialize the target_modules list\n",
    "    target_modules = []\n",
    "\n",
    "    # Add target modules for the encoder (assuming 20 layers)\n",
    "    for i in range(20):\n",
    "        target_modules.extend([\n",
    "            f\"encoder.h.{i}.attn.qkv_proj\",\n",
    "            f\"encoder.h.{i}.attn.out_proj\"\n",
    "        ])\n",
    "    \n",
    "    # Add target modules for the decoder cross-attention layers (assuming 31 layers)\n",
    "    for i in range(31):\n",
    "        if hasattr(model.decoder.transformer.h[i], 'crossattention'):\n",
    "            target_modules.extend([\n",
    "                f\"decoder.transformer.h.{i}.crossattention.qkv_proj\",\n",
    "                f\"decoder.transformer.h.{i}.crossattention.q_attn\",\n",
    "                f\"decoder.transformer.h.{i}.crossattention.out_proj\"\n",
    "            ])\n",
    "    \n",
    "    # Create the LoRA configuration\n",
    "    peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        task_type=\"SEQ2SEQ_LM\",\n",
    "        target_modules=target_modules\n",
    "    )\n",
    "    \n",
    "    # Apply the LoRA adapter to the model\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    print(\"After applying lora \"+get_model_size(model))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e04c971c-a040-4b89-9945-dfbdde6934ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from peft import LoraConfig\n",
    "\n",
    "# def apply_lora_adapter(model):\n",
    "#     # Initialize the target_modules list\n",
    "#     target_modules = []\n",
    "    \n",
    "#     # Add target modules for the encoder (assuming 20 layers)\n",
    "#     for i in range(20):\n",
    "#         target_modules.extend([\n",
    "#             f\"encoder.h.{i}.attn.qkv_proj\",\n",
    "#             f\"encoder.h.{i}.attn.out_proj\"\n",
    "#         ])\n",
    "    \n",
    "#     # Add target modules for the decoder cross-attention layers (assuming 31 layers)\n",
    "#     for i in range(31):\n",
    "#         each_decoder_layer = model.decoder.transformer.h[i]\n",
    "#         if hasattr(each_decoder_layer, 'crossattention'):\n",
    "#             target_modules.extend([\n",
    "#                 f\"decoder.h.{i}.crossattention.qkv_proj\",\n",
    "#                 f\"decoder.h.{i}.crossattention.q_attn\",\n",
    "#                 f\"decoder.h.{i}.crossattention.out_proj\"\n",
    "#             ])\n",
    "    \n",
    "#     # Create the LoRA configuration\n",
    "#     peft_config = LoraConfig(\n",
    "#         lora_alpha=4,\n",
    "#         lora_dropout=0.1,\n",
    "#         r=16,\n",
    "#         task_type=\"SEQ2SEQ_LM\",\n",
    "#         target_modules=target_modules\n",
    "#     )\n",
    "    \n",
    "#     # Apply the LoRA adapter to the model\n",
    "#     model.apply_adapter(peft_config)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e1c1d6d-03b7-4bb2-82ee-ad03b21b9297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(args, model, train_data):\n",
    "    print(f\"Starting main loop\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        report_to='tensorboard',\n",
    "        output_dir=args.save_dir,\n",
    "        overwrite_output_dir=False,\n",
    "\n",
    "        do_train=True,\n",
    "        save_strategy='epoch',\n",
    "\n",
    "        num_train_epochs=args.epochs,\n",
    "        per_device_train_batch_size=args.batch_size_per_replica,\n",
    "        gradient_accumulation_steps=args.grad_acc_steps,\n",
    "\n",
    "        learning_rate=args.lr,\n",
    "        weight_decay=0.0,\n",
    "        warmup_steps=args.lr_warmup_steps,\n",
    "\n",
    "        logging_dir=args.save_dir,\n",
    "        logging_first_step=True,\n",
    "        logging_steps=args.log_freq,\n",
    "        save_total_limit=2,\n",
    "\n",
    "        dataloader_drop_last=True,\n",
    "        dataloader_num_workers=4,\n",
    "\n",
    "        local_rank=args.local_rank,\n",
    "        deepspeed=args.deepspeed,\n",
    "        fp16=args.fp16,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    if args.local_rank in [0, -1]:\n",
    "        final_checkpoint_dir = os.path.join(args.save_dir, \"final_checkpoint\")\n",
    "        model.save_pretrained(final_checkpoint_dir)\n",
    "        print(f'  ==> Finish training and save to {final_checkpoint_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac3a06a0-ac1f-49a6-b568-21d174bba07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tokenize_data(args):\n",
    "    # Load and tokenize data\n",
    "    if os.path.exists(args.cache_data):\n",
    "        train_data = load_from_disk(args.cache_data)\n",
    "        print(f'  ==> Loaded {len(train_data)} samples')\n",
    "        return train_data\n",
    "    else:\n",
    "        datasets = load_dataset('json', data_files=args.instruct_data_path)['train']\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.load)\n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "            source = [prompt_input.format_map({'instruction': instruct, 'input': inp}) if inp != ''\n",
    "                      else prompt_no_input.format_map({'instruction': instruct})\n",
    "                      for instruct, inp in zip(examples[\"instruction\"], examples[\"input\"])]\n",
    "            target = [src + output + tokenizer.eos_token for src, output in zip(source, examples[\"output\"])]\n",
    "\n",
    "            model_inputs = tokenizer(source, max_length=args.max_len, padding=\"max_length\", truncation=True)\n",
    "            labels = tokenizer(target, max_length=args.max_len, padding=\"max_length\", truncation=True)\n",
    "            model_inputs[\"decoder_input_ids\"] = copy.deepcopy(labels[\"input_ids\"])\n",
    "\n",
    "            # changing labels: convert all tokens in the duplicate prefix prompt and the padding part to -100\n",
    "            eos_token_id = tokenizer.eos_token_id\n",
    "            for x, y in zip(model_inputs[\"input_ids\"], labels[\"input_ids\"]):\n",
    "                label_prefix_len = x.index(eos_token_id) if eos_token_id in x else len(x)\n",
    "                y[:label_prefix_len] = [-100] * label_prefix_len\n",
    "\n",
    "                if eos_token_id in y:\n",
    "                    pad_len = len(y) - y.index(eos_token_id) - 1\n",
    "                    if pad_len > 0:\n",
    "                        y[y.index(eos_token_id) + 1:] = [-100] * pad_len\n",
    "\n",
    "            # shift labels to the right as the decoder input and add decoder start token id\n",
    "            decoder_start_id = tokenizer.eos_token_id\n",
    "            for z in model_inputs[\"decoder_input_ids\"]:\n",
    "                z[1:] = z[:-1]\n",
    "                z[0] = decoder_start_id\n",
    "\n",
    "            model_inputs[\"labels\"] = copy.deepcopy(labels[\"input_ids\"])\n",
    "            model_inputs[\"decoder_attention_mask\"] = labels[\"attention_mask\"]\n",
    "            return model_inputs\n",
    "\n",
    "        train_data = datasets.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            remove_columns=datasets.column_names,\n",
    "            num_proc=64,\n",
    "            load_from_cache_file=False,\n",
    "        )\n",
    "\n",
    "        print(f'  ==> Loaded {len(train_data)} samples')\n",
    "        train_data.save_to_disk(args.cache_data)\n",
    "        print(f'  ==> Saved to {args.cache_data}')\n",
    "        return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adce8102-98ec-455e-a170-fc93f1c08ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    argsdict = vars(args)\n",
    "    print(pprint.pformat(argsdict))\n",
    "\n",
    "    # Save command to file\n",
    "    with open(os.path.join(args.save_dir, \"command.txt\"), 'w') as f:\n",
    "        f.write(pprint.pformat(argsdict))\n",
    "\n",
    "    # Load and tokenize data using the tokenizer from `args.load`. If the data is already cached, load it from there.\n",
    "    # You can customize this function to load your own data for any Seq2Seq LM tasks.\n",
    "    train_data = load_tokenize_data(args)\n",
    "\n",
    "    if args.data_num != -1:\n",
    "        train_data = train_data.select([i for i in range(args.data_num)])\n",
    "\n",
    "    # Load model from `args.load`\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(args.load, \n",
    "                                                  low_cpu_mem_usage=True, trust_remote_code=True)\n",
    "\n",
    "    print(f\"  ==> Loaded model from {args.load}, model size {model.num_parameters()}\")\n",
    "    freeze_decoder_except_xattn_codegen(model)\n",
    "    \n",
    "    # model = apply_lora(model)\n",
    "    \n",
    "    model = apply_lora_adapter(model)\n",
    "\n",
    "    run_training(args, model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea66d910-df39-4ae1-a19c-1110c578b3df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size_per_replica': 8,\n",
      " 'cache_data': '/Code generation/First_finetune/cache_data/instructions',\n",
      " 'data_num': -1,\n",
      " 'deepspeed': None,\n",
      " 'epochs': 3,\n",
      " 'fp16': False,\n",
      " 'grad_acc_steps': 16,\n",
      " 'instruct_data_path': 'output.json',\n",
      " 'load': 'Salesforce/codet5p-2b',\n",
      " 'local_rank': -1,\n",
      " 'log_freq': 10,\n",
      " 'lr': 2e-05,\n",
      " 'lr_warmup_steps': 30,\n",
      " 'max_len': 512,\n",
      " 'save_dir': '/Code generation/First_finetune/saved_models/instruct_codet5p_2b',\n",
      " 'save_freq': 500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91923cf148504de7816cf1036ec0dab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f529d23ebe474db4c192198f4b7cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/19493 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Loaded 19493 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b174b4f359b3491d81ad536fa681ffa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/19493 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Saved to /Code generation/First_finetune/cache_data/instructions\n",
      "  ==> Loaded model from Salesforce/codet5p-2b, model size 3112427008\n",
      "Para before freezing: 3112427008, trainable para: 3112M\n",
      "Para after freezing: 3112427008, trainable para: 333M\n",
      "After applying lora 8M\n",
      "Starting main loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 3:53:26, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.957900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.995900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.996300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.965700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.975100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.989500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.937100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.849300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.969200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.874300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.873500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.793800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.787800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.818100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.872600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.763900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.770700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.798200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.780600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.827200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.793400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.769200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Finish training and save to /Code generation/First_finetune/saved_models/instruct_codet5p_2b/final_checkpoint\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"CodeT5+ instruction tuning\")\n",
    "    parser.add_argument('--data-num', default=-1, type=int)\n",
    "    parser.add_argument('--max-len', default=512, type=int)\n",
    "    parser.add_argument('--instruct-data-path', default='output.json', type=str)\n",
    "    parser.add_argument('--cache-data', default='/Code generation/First_finetune/cache_data/instructions', type=str)\n",
    "    parser.add_argument('--load', default='Salesforce/codet5p-2b', type=str)\n",
    "\n",
    "    parser.add_argument('--epochs', default=3, type=int)\n",
    "    parser.add_argument('--lr', default=2e-5, type=float)\n",
    "    parser.add_argument('--lr-warmup-steps', default=30, type=int)\n",
    "    parser.add_argument('--batch-size-per-replica', default=8, type=int)\n",
    "    parser.add_argument('--grad-acc-steps', default=16, type=int)\n",
    "    parser.add_argument('--local_rank', default=-1, type=int)\n",
    "    parser.add_argument('--deepspeed', default=None, type=str)\n",
    "    parser.add_argument('--fp16', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--save-dir', default=\"/Code generation/First_finetune/saved_models/instruct_codet5p_2b\", type=str)\n",
    "    parser.add_argument('--log-freq', default=10, type=int)\n",
    "    parser.add_argument('--save-freq', default=50, type=int)\n",
    "\n",
    "    try:\n",
    "        get_ipython\n",
    "        interactive_env = True\n",
    "    except NameError:\n",
    "        interactive_env = False\n",
    "\n",
    "    if interactive_env:\n",
    "        args = parser.parse_args(args=[])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Finish training and save to final_checkpoint\n"
     ]
    }
   ],
   "source": [
    "final_checkpoint_dir = os.path.join(\"\", \"final_checkpoint\")\n",
    "model.save_pretrained(final_checkpoint_dir)\n",
    "print(f'  ==> Finish training and save to {final_checkpoint_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
